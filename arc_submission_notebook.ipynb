{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackKeller27/ARC-Prize-2024/blob/main/arc_submission_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c05628-c946-421d-8dff-95c5410d5e14",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "f2c05628-c946-421d-8dff-95c5410d5e14"
      },
      "source": [
        "# ARC Prize 2024 Submission\n",
        "\n",
        "Jack Keller\n",
        "\n",
        "Georgia Institute of Technology\n",
        "\n",
        "jkeller44@gatech.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "717270ed-182b-4598-8f12-612cd62de60e",
      "metadata": {
        "id": "717270ed-182b-4598-8f12-612cd62de60e"
      },
      "source": [
        "# Load needed libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "828dd6cc-7da7-4bec-a211-ff9afb2e688a",
      "metadata": {
        "id": "828dd6cc-7da7-4bec-a211-ff9afb2e688a"
      },
      "source": [
        "Basic libraries like numpy, torch, matplotlib, and tqdm are already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca3d361d-d3e0-45d2-b416-803c0ad1822c",
      "metadata": {
        "id": "ca3d361d-d3e0-45d2-b416-803c0ad1822c"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# # Import arckit library\n",
        "# # Repo: https://github.com/mxbi/arckit?tab=readme-ov-file\n",
        "# # Paper: https://arxiv.org/pdf/2402.03507\n",
        "# import arckit\n",
        "\n",
        "colab = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bae22af4-5a95-40d1-ac1f-f611b77578c7",
      "metadata": {
        "id": "bae22af4-5a95-40d1-ac1f-f611b77578c7"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b4bf5a-3237-46f6-ab05-2319a0497a8b",
      "metadata": {
        "id": "c3b4bf5a-3237-46f6-ab05-2319a0497a8b"
      },
      "source": [
        "Here we are loading the training challenges and solutions (this is the public training set), the evaluation challenges and solutions (this is the public evaluation set), and the test challenges (currently a placeholder file that is a copy of the public evaluation challanges)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment this cell to run with colab\n",
        "colab = True\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCUHlJQt0us4",
        "outputId": "364226b1-3aa7-4931-817b-f156d5848842"
      },
      "id": "PCUHlJQt0us4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "207605ea-58a7-46e0-9fd2-3ee2000eece7",
      "metadata": {
        "id": "207605ea-58a7-46e0-9fd2-3ee2000eece7"
      },
      "outputs": [],
      "source": [
        "# Public training set\n",
        "if colab:\n",
        "  train_challenges_path = '/content/drive/MyDrive/Colab Notebooks/Knowledge-Based AI (ARC Prize)/ARC Prize Submission/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
        "  train_solutions_path = '/content/drive/MyDrive/Colab Notebooks/Knowledge-Based AI (ARC Prize)/ARC Prize Submission/input/arc-prize-2024/arc-agi_training_solutions.json'\n",
        "else:\n",
        "  train_challenges_path = './input/arc-prize-2024/arc-agi_training_challenges.json'\n",
        "  train_solutions_path = './input/arc-prize-2024/arc-agi_training_solutions.json'\n",
        "\n",
        "with open(train_challenges_path) as fp:\n",
        "    train_challenges = json.load(fp)\n",
        "with open(train_solutions_path) as fp:\n",
        "    train_solutions = json.load(fp)\n",
        "\n",
        "# Public evaluation set\n",
        "if colab:\n",
        "  evaluation_challenges_path = '/content/drive/MyDrive/Colab Notebooks/Knowledge-Based AI (ARC Prize)/ARC Prize Submission/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
        "  evaluation_solutions_path = '/content/drive/MyDrive/Colab Notebooks/Knowledge-Based AI (ARC Prize)/ARC Prize Submission/input/arc-prize-2024/arc-agi_training_solutions.json'\n",
        "else:\n",
        "  evaluation_challenges_path = './input/arc-prize-2024/arc-agi_training_challenges.json'\n",
        "  evaluation_solutions_path = './input/arc-prize-2024/arc-agi_training_solutions.json'\n",
        "\n",
        "with open(evaluation_challenges_path) as fp:\n",
        "    evaluation_challenges = json.load(fp)\n",
        "with open(evaluation_solutions_path) as fp:\n",
        "    evaluation_solutions = json.load(fp)\n",
        "\n",
        "# This will be the hidden test challenges (currently has a placeholder to the evaluation set)\n",
        "if colab:\n",
        "  test_challenges_path = '/content/drive/MyDrive/Colab Notebooks/Knowledge-Based AI (ARC Prize)/ARC Prize Submission/input/arc-prize-2024/arc-agi_test_challenges.json'\n",
        "else:\n",
        "  test_challenges_path = './input/arc-prize-2024/arc-agi_test_challenges.json'\n",
        "\n",
        "with open(test_challenges_path) as fp:\n",
        "    test_challenges = json.load(fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e292806c-8c0c-4efd-9c30-b3660254e4c2",
      "metadata": {
        "id": "e292806c-8c0c-4efd-9c30-b3660254e4c2"
      },
      "source": [
        "Here is an example of what a test task looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be570a8b-7105-4935-b538-5e58794406f0",
      "metadata": {
        "id": "be570a8b-7105-4935-b538-5e58794406f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb25d5f2-21dd-4e75-850c-80e023b682b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': [{'input': [[3, 2], [7, 8]]}],\n",
              " 'train': [{'input': [[8, 6], [6, 4]],\n",
              "   'output': [[8, 6, 8, 6, 8, 6],\n",
              "    [6, 4, 6, 4, 6, 4],\n",
              "    [6, 8, 6, 8, 6, 8],\n",
              "    [4, 6, 4, 6, 4, 6],\n",
              "    [8, 6, 8, 6, 8, 6],\n",
              "    [6, 4, 6, 4, 6, 4]]},\n",
              "  {'input': [[7, 9], [4, 3]],\n",
              "   'output': [[7, 9, 7, 9, 7, 9],\n",
              "    [4, 3, 4, 3, 4, 3],\n",
              "    [9, 7, 9, 7, 9, 7],\n",
              "    [3, 4, 3, 4, 3, 4],\n",
              "    [7, 9, 7, 9, 7, 9],\n",
              "    [4, 3, 4, 3, 4, 3]]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "sample_task = list(test_challenges.keys())[0]\n",
        "test_challenges[sample_task]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10e38032",
      "metadata": {
        "id": "10e38032"
      },
      "source": [
        "# Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a968846c",
      "metadata": {
        "id": "a968846c"
      },
      "source": [
        "## Define our DSL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76038ecc",
      "metadata": {
        "id": "76038ecc"
      },
      "source": [
        "Create a class which represents an individual ARC puzzle.\n",
        "\n",
        "Will contain attributes about the puzzle (size, components, etc.) along with various operations which may be applied to the puzzle to transform it.\n",
        "These operations comprise our domain-specific language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de19cae9",
      "metadata": {
        "id": "de19cae9"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Adapted from Knowledge-Based AI (CS 4635/7637) Homework 2 at Georgia Institute of Technology.\n",
        "\n",
        "Defines a class to represent an ARC Puzzle, and a list of possible operations that may be applied to the grid to transform it.\n",
        "This represents our domain-specific language (DSL).\n",
        "\n",
        "Instructor: Christopher J. MacLellan. https://chrismaclellan.com/\n",
        "\"\"\"\n",
        "\n",
        "from random import choice\n",
        "\n",
        "class ARCPuzzle():\n",
        "    \"\"\"\n",
        "    An ARC puzzle class that can be used to test different search algorithms.\n",
        "    When first created, the puzzle is in the solved state.\n",
        "\n",
        "    Contains basic, full-puzzle operations (rotate, mirror, compress, etc.) along with component-specific operations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_grid):\n",
        "        self.state = tuple((tuple(row) for row in input_grid))\n",
        "        self.path = []\n",
        "        # super().__init__(self.state, None)\n",
        "\n",
        "    # def __add_goal__(self, output_grid):\n",
        "    #     # Add goal state to the current puzzle (in the form of another ARCPuzzle instance)\n",
        "    #     self.goal_node = Node(ARCPuzzle(output_grid))\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.state)\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        if isinstance(other, ARCPuzzle):\n",
        "            return self.state == other.state\n",
        "        return False\n",
        "\n",
        "    def __ne__(self, other):\n",
        "        return not self.__eq__(other)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self)\n",
        "\n",
        "    def __str__(self):\n",
        "        out = \"\"\n",
        "        for row in self.state:\n",
        "            out += str(row) + \"\\n\"\n",
        "        return out\n",
        "\n",
        "    def copy(self):\n",
        "        \"\"\"\n",
        "        Makes a deep copy of an ARCPuzzle object.\n",
        "        \"\"\"\n",
        "        new_puzzle = ARCPuzzle(self.state)\n",
        "        new_puzzle.path = self.path.copy()\n",
        "        return new_puzzle\n",
        "\n",
        "    def randomize(self, num_shuffles):\n",
        "        \"\"\"\n",
        "        Randomizes an ARCPuzzle by executing a random action `num_suffles`\n",
        "        times.\n",
        "        \"\"\"\n",
        "        for i in range(num_shuffles):\n",
        "            actions = [a for a in self.legalActions()]\n",
        "            a = choice([a for a in self.legalActions()])\n",
        "            # print(actions, a)\n",
        "            self.executeAction(a)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def tophalf(self, grid):\n",
        "        \"\"\" upper half \"\"\"\n",
        "        return grid[:len(grid) // 2]\n",
        "\n",
        "\n",
        "    def rot90(self, grid):\n",
        "        \"\"\" clockwise rotation by 90 degrees \"\"\"\n",
        "        return tuple(zip(*grid[::-1]))\n",
        "\n",
        "\n",
        "    def hmirror(self, grid):\n",
        "        \"\"\" mirroring along horizontal \"\"\"\n",
        "        return grid[::-1]\n",
        "\n",
        "    def vmirror(self, grid):\n",
        "        \"\"\" mirroring along horizontal \"\"\"\n",
        "        return tuple(reversed(grid))\n",
        "\n",
        "    def lshift(self, grid):\n",
        "        return tuple([tuple([e for e in row if e != 0] + [0]*row.count(0))\n",
        "                      for row in grid])\n",
        "\n",
        "    def compress(self, grid):\n",
        "        \"\"\" removes frontiers \"\"\"\n",
        "        ri = [i for i, r in enumerate(grid) if len(set(r)) == 1]\n",
        "        ci = [j for j, c in enumerate(zip(*grid)) if len(set(c)) == 1]\n",
        "        return tuple([tuple([v for j, v in enumerate(r) if j not in ci])\n",
        "                      for i, r in enumerate(grid) if i not in ri])\n",
        "\n",
        "    def mapcolor(self, grid, a, b):\n",
        "        return tuple(tuple(b if e == a else e for e in row) for row in grid)\n",
        "\n",
        "    def trim(self, grid):\n",
        "        \"\"\" removes border \"\"\"\n",
        "        return tuple(r[1:-1] for r in grid[1:-1])\n",
        "\n",
        "    def executeAction(self, action):\n",
        "        \"\"\"\n",
        "        Executes an action to the ARCPuzzle object.\n",
        "\n",
        "        :param action: the action to execute\n",
        "        :type action: \"up\", \"left\", \"right\", or \"down\"\n",
        "        \"\"\"\n",
        "        if action == 'tophalf':\n",
        "            self.state = self.tophalf(self.state)\n",
        "        elif action == 'rot90':\n",
        "            self.state = self.rot90(self.state)\n",
        "        elif action == 'hmirror':\n",
        "            self.state = self.hmirror(self.state)\n",
        "        elif action == 'vmirror':\n",
        "            self.state = self.vmirror(self.state)\n",
        "        elif action == 'lshift':\n",
        "            self.state = self.lshift(self.state)\n",
        "        elif action == 'compress':\n",
        "            self.state = self.compress(self.state)\n",
        "        elif action[:8] == 'mapcolor':\n",
        "            args = action[9:-1].split(',')\n",
        "            self.state = self.mapcolor(self.state, int(args[0]), int(args[1]))\n",
        "\n",
        "    def legalActions(self):\n",
        "        \"\"\"\n",
        "        Returns an iterator to the legal actions that can be executed in the\n",
        "        current state.\n",
        "        \"\"\"\n",
        "        for action in ['tophalf', 'rot90', 'hmirror', 'vmirror', 'lshift', 'compress']:\n",
        "            yield action\n",
        "\n",
        "        for a in set(e for row in self.state for e in row):\n",
        "            for b in range(10):\n",
        "                if a == b:\n",
        "                    continue\n",
        "                yield f'mapcolor({a},{b})'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfb988fe",
      "metadata": {
        "id": "dfb988fe"
      },
      "source": [
        "## Define our search algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12fdbc34",
      "metadata": {
        "id": "12fdbc34"
      },
      "source": [
        "Let's start with a basic breadth-first-search.\n",
        "\n",
        "**Best score:** 0%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29b81679",
      "metadata": {
        "id": "29b81679"
      },
      "outputs": [],
      "source": [
        "# We need this for imposing a time limit on the search\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7438a50b",
      "metadata": {
        "id": "7438a50b"
      },
      "outputs": [],
      "source": [
        "def breadth_first_search(input_grid, output_grid, max_depth, max_seconds) -> list[str]:\n",
        "    \"\"\"\n",
        "    Searches for a sequence of transformations to convert the input_grid into\n",
        "    the output_grid.\n",
        "\n",
        "    Parameters:\n",
        "    - input_grid: The initial grid that needs to be transformed.\n",
        "    - output_grid: The target grid to achieve.\n",
        "    - max_depth: The max depth of the search.\n",
        "    - max_seconds: The max number of seconds allowed before the search times out.\n",
        "\n",
        "    Returns:\n",
        "    - A list of actions that transforms input_grid into output_grid.\n",
        "    \"\"\"\n",
        "    # Create initial problem puzzle and goal puzzle\n",
        "    start_problem = ARCPuzzle(input_grid)\n",
        "    goal_problem = ARCPuzzle(output_grid)\n",
        "\n",
        "    # Set up BFS\n",
        "    queue = []\n",
        "    visited = set([start_problem.state])\n",
        "    init_time = time.time()\n",
        "\n",
        "    queue.append(start_problem)\n",
        "    while (len(queue) > 0):\n",
        "        # Break if we've hit the time limit\n",
        "        if time.time() - init_time > max_seconds:\n",
        "            # print(print(time.time() - init_time))\n",
        "\n",
        "            # Returning None signifies timeout\n",
        "            return None\n",
        "\n",
        "        curr_prob = queue.pop(0)\n",
        "        # print(curr_prob.path)\n",
        "\n",
        "        if curr_prob == goal_problem:\n",
        "            return curr_prob.path\n",
        "\n",
        "        if len(curr_prob.path) > max_depth:\n",
        "            # we've applied more than the max_depth number of transformations\n",
        "            # move on to next possibility\n",
        "            continue\n",
        "\n",
        "        visited.add(curr_prob.state)\n",
        "\n",
        "        # Explore frontier of possible transformations\n",
        "        legal_actions = curr_prob.legalActions()\n",
        "        for action in legal_actions:\n",
        "            # print(action)\n",
        "            new_prob = curr_prob.copy()\n",
        "            new_prob.path.append(action)\n",
        "            # if len(new_prob.path) > 1:\n",
        "            #     print(new_prob.path)\n",
        "            new_prob.executeAction(action)\n",
        "\n",
        "            # print(new_prob)\n",
        "            # print(new_prob.path)\n",
        "\n",
        "            if new_prob.state not in visited:\n",
        "                queue.append(new_prob)\n",
        "\n",
        "    # Return empty if no solution found\n",
        "    return []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "821f23ad",
      "metadata": {
        "id": "821f23ad"
      },
      "source": [
        "Next let's implement best-first-search using a heuristic. This should help reduce our search time and avoid timing out.\n",
        "\n",
        "The heuristic is defined below:\n",
        "- Select the operation that minimizes the total number of differing pixels\n",
        "between the current state and the output state.\n",
        "- Each pixel that differs between the current and output grids counts as\n",
        "one difference, regardless of how much the actual values differ.\n",
        "\n",
        "**Best score**: _%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a8e10dc",
      "metadata": {
        "id": "1a8e10dc"
      },
      "outputs": [],
      "source": [
        "# from queue import PriorityQueue\n",
        "\n",
        "# We'll use heapq since it's more efficient\n",
        "import heapq\n",
        "from itertools import count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d15a7c5",
      "metadata": {
        "id": "3d15a7c5"
      },
      "outputs": [],
      "source": [
        "def best_first_search(input_grid, output_grid, max_depth, max_seconds) -> list[str]:\n",
        "    \"\"\"\n",
        "    Searches for a sequence of transformations to convert the input_grid into\n",
        "    the output_grid.\n",
        "\n",
        "    Relies on a heuristic: select the action which minimizes the number of different pixels between the current state and goal state.\n",
        "\n",
        "    Parameters:\n",
        "    - input_grid: The initial grid that needs to be transformed.\n",
        "    - output_grid: The target grid to achieve.\n",
        "    - max_depth: The max depth of the search.\n",
        "    - max_seconds: The max number of seconds allowed before the search times out.\n",
        "\n",
        "    Returns:\n",
        "    - A list of actions that transforms input_grid into output_grid.\n",
        "    \"\"\"\n",
        "    # Create initial problem puzzle and goal puzzle\n",
        "    start_problem = ARCPuzzle(input_grid)\n",
        "    goal_problem = ARCPuzzle(output_grid)\n",
        "\n",
        "    # Set up the search\n",
        "    priority_queue = [] # elements are of form (# of different pixels from goal, current state)\n",
        "    visited = set([start_problem.state])\n",
        "    init_time = time.time()\n",
        "    counter = count() # unique counter for each entry in the priority queue (in case heuristic's are tied)\n",
        "\n",
        "    heapq.heappush(priority_queue, (0, next(counter), start_problem))\n",
        "    while (len(priority_queue) > 0):\n",
        "        # Break if we've hit the time limit\n",
        "        if time.time() - init_time > max_seconds:\n",
        "            # print(print(time.time() - init_time))\n",
        "\n",
        "            # Returning None signifies timeout\n",
        "            return None\n",
        "\n",
        "        _, _, curr_prob = heapq.heappop(priority_queue)\n",
        "        # print(curr_prob.path)\n",
        "\n",
        "        if curr_prob == goal_problem:\n",
        "            # Solution found\n",
        "            return curr_prob.path\n",
        "\n",
        "        if len(curr_prob.path) > max_depth:\n",
        "            # we've applied more than the max_depth number of transformations\n",
        "            # move on to next possibility\n",
        "            continue\n",
        "\n",
        "        visited.add(curr_prob.state)\n",
        "\n",
        "        # Explore frontier of possible transformations\n",
        "        legal_actions = curr_prob.legalActions()\n",
        "        for action in legal_actions:\n",
        "            # print(action)\n",
        "            new_prob = curr_prob.copy()\n",
        "            new_prob.path.append(action)\n",
        "            # if len(new_prob.path) > 1:\n",
        "            #     print(new_prob.path)\n",
        "            new_prob.executeAction(action)\n",
        "\n",
        "            # print(new_prob)\n",
        "            # print(new_prob.path)\n",
        "\n",
        "            if new_prob.state not in visited:\n",
        "                # Calculate heuristic (# of different pixels)\n",
        "                h = np.sum(new_prob.state != goal_problem.state)\n",
        "                heapq.heappush(priority_queue, (h, next(counter), new_prob))\n",
        "\n",
        "    # Return empty if no solution found\n",
        "    return []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1049c17a",
      "metadata": {
        "id": "1049c17a"
      },
      "source": [
        "Finally, we'll implement a bidirectional version of our best-first-search above. Hopefully, this will reduce search time significantly.\n",
        "\n",
        "**Best score:** _%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10dfb16c",
      "metadata": {
        "id": "10dfb16c"
      },
      "outputs": [],
      "source": [
        "def bidirectional_best_first_search(input_grid, output_grid, max_depth, max_seconds) -> list[str]:\n",
        "    \"\"\"\n",
        "    Searches for a sequence of transformations to convert the input_grid into\n",
        "    the output_grid using a bidirectional heuristic approach.\n",
        "\n",
        "    Parameters:\n",
        "    - input_grid: The initial grid that needs to be transformed.\n",
        "    - output_grid: The target grid to achieve.\n",
        "    - max_depth: The max depth of the search.\n",
        "    - max_seconds: The max number of seconds allowed before the search times out.\n",
        "\n",
        "    Returns:\n",
        "    - A list of actions that transforms input_grid into output_grid, or None if it times out.\n",
        "    \"\"\"\n",
        "    # Initialize problems from both start and goal states\n",
        "    start_problem = ARCPuzzle(input_grid)\n",
        "    goal_problem = ARCPuzzle(output_grid)\n",
        "\n",
        "    # Initialize priority queues and visited sets for both directions\n",
        "    start_queue = []\n",
        "    goal_queue = []\n",
        "    counter = count() # unique counter for each entry in the priority queue (in case heuristic's are tied)\n",
        "    heapq.heappush(start_queue, (0, next(counter), start_problem))\n",
        "    heapq.heappush(goal_queue, (0, next(counter), goal_problem))\n",
        "\n",
        "    # Here, we need to keep track of both states and paths in the visited set, since we'll need to stitch the start and goal paths together\n",
        "    start_visited = {start_problem.state: start_problem.path}\n",
        "    goal_visited = {goal_problem.state: goal_problem.path}\n",
        "\n",
        "    # Keep track of initial time to check if the search times out\n",
        "    init_time = time.time()\n",
        "\n",
        "    while start_queue and goal_queue:\n",
        "        # Break if time limit is reached\n",
        "        if time.time() - init_time > max_seconds:\n",
        "            return None  # Timeout\n",
        "\n",
        "        # Expand from the start side\n",
        "        _, _, curr_start_prob = heapq.heappop(start_queue)\n",
        "\n",
        "        if curr_start_prob.state in goal_visited:\n",
        "            # Paths meet; combine and return\n",
        "            return curr_start_prob.path + goal_visited[curr_start_prob.state][::-1]\n",
        "\n",
        "        # Check depth limit for start side\n",
        "        if len(curr_start_prob.path) <= max_depth:\n",
        "\n",
        "            # This is where we iterate through the possible operations in the DSL\n",
        "            for action in curr_start_prob.legalActions():\n",
        "                new_start_prob = curr_start_prob.copy()\n",
        "                new_start_prob.path.append(action)\n",
        "                new_start_prob.executeAction(action)\n",
        "\n",
        "                # If the state is unvisited, compute heuristic and add to queue\n",
        "                if new_start_prob.state not in start_visited:\n",
        "                    h_start = np.sum(new_start_prob.state != goal_problem.state)  # heuristic\n",
        "                    heapq.heappush(start_queue, (h_start, next(counter), new_start_prob))\n",
        "                    start_visited[new_start_prob.state] = new_start_prob.path # add to visited set\n",
        "\n",
        "        # Expand from the goal side\n",
        "        _, _, curr_goal_prob = heapq.heappop(goal_queue)\n",
        "\n",
        "        if curr_goal_prob.state in start_visited:\n",
        "            # Paths meet; combine and return\n",
        "            return start_visited[curr_goal_prob.state] + curr_goal_prob.path[::-1]\n",
        "\n",
        "        # Check depth limit for goal side\n",
        "        if len(curr_goal_prob.path) <= max_depth:\n",
        "            for action in curr_goal_prob.legalActions():\n",
        "                new_goal_prob = curr_goal_prob.copy()\n",
        "                new_goal_prob.path.append(action)\n",
        "                new_goal_prob.executeAction(action)\n",
        "\n",
        "                # If the state is unvisited, compute heuristic and add to queue\n",
        "                if new_goal_prob.state not in goal_visited:\n",
        "                    h_goal = np.sum(new_goal_prob.state != start_problem.state)  # heuristic\n",
        "                    heapq.heappush(goal_queue, (h_goal, next(counter), new_goal_prob))\n",
        "                    goal_visited[new_goal_prob.state] = new_goal_prob.path # add to visited set\n",
        "\n",
        "    # Return empty if no solution found\n",
        "    return []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e82a26ee",
      "metadata": {
        "id": "e82a26ee"
      },
      "source": [
        "## Solve the ARC tasks (generate hypotheses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0f514eb",
      "metadata": {
        "id": "b0f514eb"
      },
      "source": [
        "This function takes the train and test inputs for a singular ARC task and predicts an answer using search.\n",
        "\n",
        "Possible search algorithms:\n",
        "- Breadth-first-search\n",
        "- Best-first-search (# of different pixels heuristic)\n",
        "- *Bidirectional* best-first-search (default)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze the input and output grids\n",
        "In an attempt to better understand the search problems, and possibly narrow down the search space of possible transformations, we must:\n",
        "- Determine the size of the output grid\n",
        "- Detect components in each grid and common components in both\n",
        "- Use this information to narrow down the list of possible (or likely) DSL operations\n",
        "\n",
        "In this section, helper functions will be implemented to accomplish each of these tasks."
      ],
      "metadata": {
        "id": "7_Z4fcybkUjQ"
      },
      "id": "7_Z4fcybkUjQ"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Determine the size of the output grid for a given ARC problem.\n",
        "\n",
        "Calculated by the input to output size ratio.\n",
        "\"\"\"\n",
        "\n",
        "def determine_output_grid_size(train_inputs, train_outputs, test_input):\n",
        "  # For every ARC problem, the ratio of input size:output size is consistent throughout the training examples\n",
        "  # We can use this to predict the test output size\n",
        "  for input_grid, output_grid in zip(train_inputs, train_outputs):\n",
        "    input_grid = np.array(input_grid)\n",
        "    output_grid = np.array(output_grid)\n",
        "\n",
        "    y_ratio = input_grid.shape[0] / output_grid.shape[0]\n",
        "    x_ratio = input_grid.shape[1] / output_grid.shape[1]\n",
        "\n",
        "    output_shape = (int(test_input.shape[0] * y_ratio), int(test_input.shape[1] * x_ratio))\n",
        "    return output_shape\n"
      ],
      "metadata": {
        "id": "dfPRTaWzj8Ot"
      },
      "id": "dfPRTaWzj8Ot",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "084b6259",
      "metadata": {
        "id": "084b6259"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Given pairs of training inputs and outputs, and the test input, predict the output.\n",
        "\"\"\"\n",
        "\n",
        "def make_prediction(train_inputs, train_outputs, test_input, search=bidirectional_best_first_search, max_search_depth=3, max_search_seconds=5):\n",
        "    hypothesis = None\n",
        "    secondary_hypothesis = None\n",
        "    timed_out = False\n",
        "\n",
        "    # print(train_inputs)\n",
        "    # print(train_outputs)\n",
        "\n",
        "    for input_grid, output_grid in zip(train_inputs, train_outputs):\n",
        "        if hypothesis is None:\n",
        "            # Generate initial hypothesis\n",
        "            hypothesis = search(input_grid, output_grid, max_depth=max_search_depth, max_seconds=max_search_seconds)\n",
        "            # print(hypothesis)\n",
        "        else:\n",
        "            # Test exisiting hypothesis\n",
        "            input_puzzle = ARCPuzzle(input_grid)\n",
        "            output_puzzle = ARCPuzzle(output_grid)\n",
        "\n",
        "            for action in hypothesis:\n",
        "                input_puzzle.executeAction(action)\n",
        "\n",
        "            if input_puzzle.__eq__(output_puzzle):\n",
        "                # Hypothesis is correct, keep it\n",
        "                continue\n",
        "            else:\n",
        "                # Save secondary hypothesis\n",
        "                secondary_hypothesis = hypothesis\n",
        "\n",
        "                # Regenerate primary hypothesis\n",
        "                hypothesis = search(input_grid, output_grid, max_depth=max_search_depth, max_seconds=max_search_seconds)\n",
        "\n",
        "    # After iterating through the test data, perform final hypotheses on test input\n",
        "    test_puzzle_1 = ARCPuzzle(test_input)\n",
        "    test_puzzle_2 = test_puzzle_1.copy()\n",
        "\n",
        "    if hypothesis is None:\n",
        "        timed_out = True\n",
        "    else:\n",
        "        # Generate primary prediction\n",
        "        for action in hypothesis:\n",
        "            try:\n",
        "                test_puzzle_1.executeAction(action)\n",
        "            except:\n",
        "                print(f'Action {action} failed')\n",
        "\n",
        "        if secondary_hypothesis is not None:\n",
        "            # Generate secondary prediction\n",
        "            for action in secondary_hypothesis:\n",
        "                try:\n",
        "                    test_puzzle_2.executeAction(action)\n",
        "                except:\n",
        "                    print(f'Action {action} failed')\n",
        "\n",
        "    # Will return initial state if solution wasn't found or search timed out\n",
        "    primary_prediction = test_puzzle_1.state\n",
        "    secondary_prediction = test_puzzle_2.state\n",
        "\n",
        "    return primary_prediction, secondary_prediction, timed_out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f34083-882b-4fb9-b5fd-92dd75772dc3",
      "metadata": {
        "id": "d1f34083-882b-4fb9-b5fd-92dd75772dc3"
      },
      "source": [
        "# Generating a submission\n",
        "\n",
        "To generate a submission you need to output a file called `submission.json` that has the following format:\n",
        "\n",
        "```\n",
        "{\"00576224\": [{\"attempt_1\": [[0, 0], [0, 0]], \"attempt_2\": [[0, 0], [0, 0]]}],\n",
        " \"009d5c81\": [{\"attempt_1\": [[0, 0], [0, 0]], \"attempt_2\": [[0, 0], [0, 0]]}],\n",
        " \"12997ef3\": [{\"attempt_1\": [[0, 0], [0, 0]], \"attempt_2\": [[0, 0], [0, 0]]},\n",
        "              {\"attempt_1\": [[0, 0], [0, 0]], \"attempt_2\": [[0, 0], [0, 0]]}],\n",
        " ...\n",
        "}\n",
        "```\n",
        "\n",
        "In this case, the task ids come from `test_challenges`. There may be multiple (i.e., >1) test items per task. Therefore, the dictionary has a list of dicts for each task. These submission dictionaries should appear in the same order as the test items from `test_challenges`. Additionally, you can provide two attempts for each test item. In fact, you **MUST** provide two attempts. If you only want to generate a single attempt, then just submit the same answer for both attempts (or submit an empty submission like the ones shown in the example snippit just above.\n",
        "\n",
        "Here is how we might create a blank submission:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e25a0fb-e206-4505-b597-8863c41c7e48",
      "metadata": {
        "id": "5e25a0fb-e206-4505-b597-8863c41c7e48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3aadc4-13f0-4fd2-92ed-03ba245574f0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▋         | 25/400 [02:10<15:23,  2.46s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 41/400 [03:19<22:17,  3.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 42/400 [03:27<30:15,  5.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 55/400 [04:39<36:00,  6.26s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▋        | 65/400 [05:07<17:37,  3.16s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 77/400 [06:05<15:22,  2.85s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 82/400 [06:21<14:20,  2.71s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 88/400 [06:30<09:43,  1.87s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 89/400 [06:31<08:19,  1.61s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▎       | 90/400 [06:31<06:41,  1.29s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 93/400 [06:33<04:16,  1.20it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▋       | 106/400 [07:34<28:28,  5.81s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 108/400 [08:02<48:10,  9.90s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 110/400 [08:03<28:10,  5.83s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 111/400 [08:04<22:47,  4.73s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 121/400 [08:33<09:27,  2.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 136/400 [09:11<18:12,  4.14s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 144/400 [09:50<15:57,  3.74s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 149/400 [09:51<05:01,  1.20s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 152/400 [09:52<02:49,  1.46it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 155/400 [10:03<07:28,  1.83s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|███▉      | 159/400 [10:05<03:47,  1.06it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|████      | 164/400 [10:20<06:14,  1.59s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 177/400 [10:55<08:54,  2.40s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 179/400 [10:56<06:05,  1.65s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 211/400 [13:00<08:11,  2.60s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 224/400 [13:45<07:07,  2.43s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 225/400 [13:46<05:53,  2.02s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|█████▉    | 238/400 [14:35<13:54,  5.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|█████▉    | 239/400 [14:36<10:25,  3.88s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 252/400 [15:12<09:34,  3.88s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 264/400 [16:14<10:59,  4.85s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▋   | 266/400 [16:18<08:03,  3.61s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 272/400 [17:12<12:39,  5.93s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 277/400 [18:07<16:47,  8.19s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 297/400 [18:43<06:46,  3.95s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▋  | 306/400 [19:27<05:14,  3.35s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 312/400 [19:39<02:32,  1.74s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 321/400 [20:13<03:26,  2.62s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 329/400 [20:49<05:33,  4.69s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 336/400 [20:51<01:25,  1.33s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▋ | 345/400 [21:42<03:32,  3.86s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 350/400 [21:54<01:41,  2.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 356/400 [22:39<04:00,  5.48s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 364/400 [23:12<01:49,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 369/400 [24:07<04:41,  9.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 376/400 [24:53<01:36,  4.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 379/400 [24:53<00:36,  1.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 382/400 [25:09<01:03,  3.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 394/400 [26:16<00:22,  3.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n",
            "Action compress failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 398/400 [26:24<00:05,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action compress failed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [26:25<00:00,  3.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64 tasks timed out\n",
            "max search depth: 3\n",
            "max search seconds: 5\n"
          ]
        }
      ],
      "source": [
        "# Create an empty submission dict for output\n",
        "submission = {}\n",
        "\n",
        "# Define hyperparameters and search type\n",
        "timed_out_count = 0\n",
        "max_search_depth = 3\n",
        "max_search_seconds = 5\n",
        "\n",
        "# Options: breadth_first_search, best_first_search, bidirectional_best_first_search\n",
        "search_type = bidirectional_best_first_search\n",
        "\n",
        "# Iterate over the test items and build up submission answers\n",
        "for key, task in tqdm(test_challenges.items()):\n",
        "    # Use to test a specific task\n",
        "    # count +=1\n",
        "    # if count < 150:\n",
        "    #     continue\n",
        "\n",
        "    # Here are the task's training inputs and outputs\n",
        "    train_inputs = [item['input'] for item in task['train']]\n",
        "    train_outputs = [item['output'] for item in task['train']]\n",
        "    # print(train_inputs)\n",
        "    # print(train_outputs)\n",
        "\n",
        "    # Get test input\n",
        "    test_input = [item['input'] for item in task['test']]\n",
        "    # print(test_input)\n",
        "\n",
        "    # Here we generate outputs for each test item.\n",
        "    submission[key] = []\n",
        "\n",
        "    primary_prediction, secondary_prediction, timed_out = make_prediction(train_inputs, train_outputs, test_input, search_type, max_search_depth, max_search_seconds)\n",
        "    # print(timed_out)\n",
        "    if timed_out:\n",
        "        timed_out_count += 1\n",
        "    # print(prediction)\n",
        "\n",
        "    # add predictions to submission json\n",
        "    # NOTE: if a primary or secondary hypothesis wasn't found, predictions will be the initial state of the grid\n",
        "    # blank_prediction = [[0, 0], [0, 0]]\n",
        "    submission[key] = [{'attempt_1': primary_prediction, 'attempt_2': secondary_prediction} for item in task['test']]\n",
        "\n",
        "# Print number of tasks that timed out\n",
        "print(f'{timed_out_count} tasks timed out')\n",
        "print(f'max search depth: {max_search_depth}')\n",
        "print(f'max search seconds: {max_search_seconds}')\n",
        "\n",
        "# Here we write the submissions to file, so that they will get evaluated\n",
        "with open('submission.json', 'w') as fp:\n",
        "    json.dump(submission, fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d3d827-8f78-47d4-8bc7-3c07cfc996c2",
      "metadata": {
        "id": "d7d3d827-8f78-47d4-8bc7-3c07cfc996c2"
      },
      "source": [
        "Here is what our submission for the test task above looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07d83daa-496f-4cad-8550-876d115c4a3e",
      "metadata": {
        "id": "07d83daa-496f-4cad-8550-876d115c4a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5935ce47-5f4d-43a9-e7a7-b6271958f932"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'attempt_1': (), 'attempt_2': ()}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "submission[sample_task]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "879f7599",
      "metadata": {
        "id": "879f7599"
      },
      "source": [
        "# Scoring Your Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c39df0c1",
      "metadata": {
        "id": "c39df0c1"
      },
      "outputs": [],
      "source": [
        "def score_submission():\n",
        "    if colab:\n",
        "      sol_path = '/content/drive/MyDrive/Colab Notebooks/Knowledge-Based AI (ARC Prize)/ARC Prize Submission/input/arc-prize-2024/arc-agi_evaluation_solutions.json'\n",
        "    else:\n",
        "      sol_path = './input/arc-prize-2024/arc-agi_evaluation_solutions.json'\n",
        "\n",
        "    with open(sol_path, 'r') as sol_file:\n",
        "        solutions = json.load(sol_file)\n",
        "\n",
        "    with open('submission.json', 'r') as sub_file:\n",
        "        submission = json.load(sub_file)\n",
        "\n",
        "    overall_score = 0\n",
        "\n",
        "    for task in solutions:\n",
        "        score = 0\n",
        "        for i, answer in enumerate(solutions[task]):\n",
        "            attempt1_correct = submission[task][i]['attempt_1'] == answer\n",
        "            attempt2_correct = submission[task][i]['attempt_2'] == answer\n",
        "            score += int(attempt1_correct or attempt2_correct)\n",
        "\n",
        "        score /= len(solutions[task])\n",
        "\n",
        "        overall_score += score\n",
        "\n",
        "\n",
        "    print(overall_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6818bb2",
      "metadata": {
        "id": "b6818bb2"
      },
      "source": [
        "Score the most recently ran submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b131fe58",
      "metadata": {
        "id": "b131fe58",
        "outputId": "e2de5f22-7ed2-44dc-fb47-49effcbf5a84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "score_submission()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6466c66-c324-44c2-8e05-3860e0fe1fdd",
      "metadata": {
        "id": "f6466c66-c324-44c2-8e05-3860e0fe1fdd"
      },
      "source": [
        "# Confused about where to get started?\n",
        "\n",
        "If you're not sure what an initial solution might look like, then consider looking at public notebooks here: https://www.kaggle.com/competitions/arc-prize-2024/code or joining the public discussion here: https://www.kaggle.com/competitions/arc-prize-2024/discussion.\n",
        "\n",
        "One example notebook that uses a very simple knowledge-based approach is this one: https://www.kaggle.com/code/michaelhodel/program-synthesis-starter-notebook/notebook, which conducts search over a space of domain specific block languages to form hypotheses and then applies these to test items."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}